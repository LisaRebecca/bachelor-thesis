\chapter{Conclusion and Outlook}
\section{Conclusion}

% Zusammenfassung der Aufgabe
The task for this thesis is to identify means on how information from invoice documents can be extracted. Also, the question is how this information can provide business insights.

%Zusammenfassung der Lösung
The solution consists of a full data mining project. Firstly, a suitable dataset is identified. The second step is forming an understanding on the business dimension of the problem. This is followed by an exploration of the data, and an evaluation of the dataset. After this, the data is prepared. The data is transformed into a structured tabular format, then cleaned. Further, a feature extraction mechanism maps textual content onto vectors. Each vector represents a line item from an invoice. These line item descriptions are grouped into clusters with the k-Means algorithm. The result is a 512-dimensional vector space of 79 741 data points, which are contained in 3250 clusters. Each cluster contains invoice items which concern similar topics. The topics of each cluster are described through the three words in the cluster which describe its content the best. Finally, all clusters are visualized in a dashboard. The deployment of this solution showcases the clusters with their associated cost. 

% Zusammenfassung der Bewertung der Lösung
The analysis in adds value to real business documents because it automates a process which would otherwise be highly time-consuming. By aggregating expense categories with respect to their associated spending, a broad overview on the largest expenses is created. The spending of a company or parts of it can now be analyzed on a high-level perspective, without the need of analyzing individual invoices.

\section{Outlook}

% Was konnte nicht bearbeitet werden, wäre aber sinnvoll?
This thesis presents a full data mining workflow. Still, there are limitations to the presented solution.

The dataset is a static collection of documents. An improvement would be to use a data platform from which the data can be streamed. This can be from inside an \ac{ERP} system, or a connected Data Platform such as SAP Data Intelligence. A solution with larger data sets also requires more computing power. One offering to use is the SAP AI Foundation. With hyperscaler-agnostic deployment and operating options, AI Core is a viable option to make this solution enterprise-ready.

There are also some further options to be tried out with the analysis. For example, the cluster identity is binary. For natural language, this quite limits the interpretability. Sentences can have different meanings depending on the context, but sentences can also be grouped into logical units according to many different measures. By forming sparse clusters, in which the cluster identity is distributed, topics can be represented more realistically. 

Exploring how the \ac{BERT} model can be fine-tuned is also an interesting topic for further research. While \ac{BERT} can account for out-of vocabulary words, it lacks understanding of those. Especially, very specific business-related terms are often misinterpreted. With fine-tuning \ac{BERT} on a corpus with relevant terms to the field of business, the classification can likely be improved.

This thesis explores two clustering mechanisms in detail. Other algorithms such as MeanShift, Affinity Propagation or Spectral Clustering are also interesting to evaluate with respect to this problem.

While the generated cluster labels were quite speaking, they require interpretation effort from the reader. It would be desirable to generate more generalized labels, for example summarizing "tonic", "gin" and "teinacher" into the label "beverages".

% Welche nächsten Fragestellungen/Schritte haben sich durch die Arbeit ergeben?
The next question, further research can investigate is how this solution can be integrated into SAP's existing offerings. Section \ref{section:selected-dataset} explains that the data is already used in the context of document information extraction. Both solutions can be connected, creating a digitization accelerator, allowing a pipeline from paper to insight. Paper-based documents can be scanned, fed into the information extraction service, and processed with the presented solution. The result is an insight into spending, which would otherwise only be possible with tremendous time effort.



